---
---

@INPROCEEDINGS{MLSP,
  abbr={MLSP},
  author={Zhao, Yifei and Champagne, Benoit},
  booktitle={2022 IEEE 32nd International Workshop on Machine Learning for Signal Processing (MLSP)}, 
  title={An Efficient Transformer-Based Model for Voice Activity Detection}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Voice Activity Detection (VAD) aims to distinguish, at a given time, between desired speech and non-speech. Although many state-of-the-art approaches for increasing the performance of VAD have been proposed, they are still not robust enough to be applied under adverse noise conditions with low Signal-to-Noise Ratio (SNR). To deal with this issue, we propose a novel transformer-based architecture for VAD with reduced computational complexity by implementing efficient depth-wise convolutions on feature patches. The proposed model, named Tr-VAD, demonstrates better performance compared to baseline methods from the literature in a variety of scenarios considered with the smallest possible number of parameters. The results also indicate that the use of a combination of Audio Fingerprinting (AFP) features with Tr-VAD can guarantee better performance.},
  keywords={},
  doi={10.1109/MLSP55214.2022.9943501},
  ISSN={2161-0371},
  month={Aug},
  url={https://ieeexplore.ieee.org/document/9943501},
  html={https://ieeexplore.ieee.org/document/9943501},
  dimensions={true},
  selected={true}
}

@INPROCEEDINGS{ICASSP,
  abbr={ICASSP},
  author={Zhao, Yifei and Attabi, Yazid and Champagne, Benoit and Zhu, Wei-Ping},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Complex IRM-Aware Training for Voice Activity Detection Using Attention Model}, 
  year={2022},
  volume={},
  number={},
  pages={3698-3702},
  abstract={Although many state-of-the-art approaches for improving the accuracy of Voice Activity Detection (VAD) have been proposed, their performance under adverse noise conditions with low Signal-to-Noise Ratio (SNR) remains limited. In this paper, we introduce a novel attention model-based deep neural network (DNN) architecture for VAD which takes advantage of complex Ideal Ratio Mask (cIRM). The proposed model, named AM-cIRM, consists of three sequential modules: extraction of cIRM features from the noisy speech using a DNN-based architecture; combination of cIRM with log-Mel spectrogram features along with temporal contextual extension; and VAD using an attention model that exploits the spectro-temporal information in the transformed features. Experimental results show that the proposed AM-cIRM achieves improved VAD performance when compared to state-of-the-art methods under different noise conditions.},
  keywords={},
  doi={10.1109/ICASSP43922.2022.9746261},
  ISSN={2379-190X},
  month={May},
  url={https://ieeexplore.ieee.org/abstract/document/9746261},
  html={https://ieeexplore.ieee.org/abstract/document/9746261},
  dimensions={true},
  selected={true}
}
